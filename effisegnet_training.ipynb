{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57914608",
   "metadata": {},
   "source": [
    "# EffiSegNet Training with EfficientNet V2-S\n",
    "\n",
    "This notebook demonstrates training the improved EffiSegNet model using EfficientNet V2-S as the backbone for medical image segmentation.\n",
    "\n",
    "## Dataset Structure\n",
    "- Train/Image/ (.jpg files)\n",
    "- Train/Mask/ (.png files, binary 0-255)\n",
    "- Val/Image/ (.jpg files) \n",
    "- Val/Mask/ (.png files, binary 0-255)\n",
    "- Test/Image/ (.jpg files, no masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import torch\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Import custom modules\n",
    "from models.effisegnet import EffiSegNetBN\n",
    "from datamodule import CustomSegDataset\n",
    "from network_module import Net\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "L.seed_everything(42, workers=True)\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    'model_name': 'efficientnet_v2_s',\n",
    "    'img_size': (384, 384),\n",
    "    'batch_size': 4,  # Reduced batch size for V2-S\n",
    "    'learning_rate': 1e-4,\n",
    "    'max_epochs': 100,\n",
    "    'num_workers': 2,  # Reduced for stability\n",
    "    'ch': 64,\n",
    "    'pretrained': True,\n",
    "    'freeze_encoder': False,\n",
    "    'deep_supervision': False,\n",
    "    'data_root': './data'  # Update this path to your data directory\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the improved EffiSegNet model with EfficientNet V2-S\n",
    "model = EffiSegNetBN(\n",
    "    ch=CONFIG['ch'],\n",
    "    pretrained=CONFIG['pretrained'],\n",
    "    freeze_encoder=CONFIG['freeze_encoder'],\n",
    "    deep_supervision=CONFIG['deep_supervision'],\n",
    "    model_name=CONFIG['model_name']\n",
    ")\n",
    "\n",
    "print(f\"Model initialized: {CONFIG['model_name']}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a393e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "dataset = CustomSegDataset(\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    root_dir=CONFIG['data_root'],\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    img_size=CONFIG['img_size']\n",
    ")\n",
    "\n",
    "# Setup dataset\n",
    "dataset.setup()\n",
    "\n",
    "print(f\"Dataset initialized:\")\n",
    "print(f\"  Train samples: {len(dataset.train_set)}\")\n",
    "print(f\"  Validation samples: {len(dataset.val_set)}\")\n",
    "print(f\"  Test samples: {len(dataset.test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e556ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample data\n",
    "def visualize_samples(dataset, num_samples=4):\n",
    "    train_loader = dataset.train_dataloader()\n",
    "    batch = next(iter(train_loader))\n",
    "    images, masks = batch\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 8))\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Denormalize image for visualization\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        mask = masks[i][0].cpu().numpy()\n",
    "        \n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].set_title(f'Image {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        axes[1, i].imshow(mask, cmap='gray')\n",
    "        axes[1, i].set_title(f'Mask {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Only visualize if we have training data\n",
    "if len(dataset.train_set) > 0:\n",
    "    visualize_samples(dataset)\n",
    "else:\n",
    "    print(\"No training data found. Please check your data directory structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79989fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training components\n",
    "from monai.losses import DiceCELoss\n",
    "from lightning.pytorch import loggers\n",
    "import torch.optim as optim\n",
    "\n",
    "# Loss function\n",
    "criterion = DiceCELoss(include_background=False, sigmoid=True)\n",
    "\n",
    "# Create scheduler class that will be instantiated later\n",
    "class CosineScheduler:\n",
    "    def __init__(self, T_max):\n",
    "        self.T_max = T_max\n",
    "    \n",
    "    def __call__(self, optimizer):\n",
    "        return optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, \n",
    "            T_max=self.T_max, \n",
    "            eta_min=1e-6\n",
    "        )\n",
    "\n",
    "scheduler_class = CosineScheduler(CONFIG['max_epochs'])\n",
    "\n",
    "# Initialize network module\n",
    "net = Net(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optim.AdamW,\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    scheduler=scheduler_class\n",
    ")\n",
    "\n",
    "# Logger\n",
    "logger = loggers.TensorBoardLogger(\"logs/\", name=f\"{CONFIG['model_name']}_training\")\n",
    "\n",
    "print(\"Training components initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator='auto',\n",
    "    max_epochs=CONFIG['max_epochs'],\n",
    "    log_every_n_steps=10,\n",
    "    logger=logger,\n",
    "    deterministic='warn',\n",
    "    enable_checkpointing=True,\n",
    "    default_root_dir='./checkpoints',\n",
    "    gradient_clip_val=1.0,  # Add gradient clipping for stability\n",
    "    accumulate_grad_batches=1  # Gradient accumulation if needed\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized!\")\n",
    "print(f\"Training will run for {CONFIG['max_epochs']} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038635d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "try:\n",
    "    trainer.fit(net, dataset)\n",
    "    print(\"Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Training failed with error: {e}\")\n",
    "    print(\"Please check your data directory structure and paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"Running validation...\")\n",
    "val_results = trainer.validate(net, dataset)\n",
    "print(\"Validation results:\", val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model (if test set has ground truth)\n",
    "# Uncomment if your test set has ground truth masks\n",
    "# print(\"Running test...\")\n",
    "# test_results = trainer.test(net, dataset)\n",
    "# print(\"Test results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fde70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set and save results\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_and_save_test_results(model, dataset, output_dir=\"./predictions\"):\n",
    "    \"\"\"\n",
    "    Predict on test set and save mask predictions\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loader = dataset.test_dataloader()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, image_paths) in enumerate(test_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                model = model.cuda()\n",
    "            \n",
    "            # Forward pass\n",
    "            if hasattr(model.model, 'deep_supervision') and model.model.deep_supervision:\n",
    "                logits, _ = model(images)\n",
    "            else:\n",
    "                logits = model(images)\n",
    "            \n",
    "            # Convert to probabilities and then to binary masks\n",
    "            probs = torch.sigmoid(logits)\n",
    "            masks = (probs > 0.5).float()\n",
    "            \n",
    "            # Save each prediction\n",
    "            for i, img_path in enumerate(image_paths):\n",
    "                # Get original filename without extension\n",
    "                filename = Path(img_path).stem\n",
    "                \n",
    "                # Resize mask back to original size if needed\n",
    "                mask = masks[i, 0].cpu().numpy()\n",
    "                mask = (mask * 255).astype(np.uint8)\n",
    "                \n",
    "                # Save mask\n",
    "                save_path = os.path.join(output_dir, f\"{filename}_pred.png\")\n",
    "                cv2.imwrite(save_path, mask)\n",
    "                \n",
    "                if batch_idx == 0 and i < 4:  # Visualize first few predictions\n",
    "                    plt.figure(figsize=(10, 5))\n",
    "                    \n",
    "                    # Original image\n",
    "                    img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "                    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                    img = np.clip(img, 0, 1)\n",
    "                    \n",
    "                    plt.subplot(1, 2, 1)\n",
    "                    plt.imshow(img)\n",
    "                    plt.title(f'Original Image: {filename}')\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    plt.imshow(mask, cmap='gray')\n",
    "                    plt.title(f'Predicted Mask: {filename}')\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "    \n",
    "    print(f\"Predictions saved to: {output_dir}\")\n",
    "\n",
    "# Run prediction\n",
    "predict_and_save_test_results(net, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05df31",
   "metadata": {},
   "source": [
    "## Training Summary\n",
    "\n",
    "The training process is now complete! Here's what was accomplished:\n",
    "\n",
    "1. **Model Architecture**: Used improved EffiSegNet with EfficientNet V2-S backbone\n",
    "2. **Training**: Trained on your custom dataset with Train/Val splits\n",
    "3. **Evaluation**: Validated the model performance\n",
    "4. **Prediction**: Generated predictions for test images and saved them to `./predictions/` folder\n",
    "\n",
    "### Next Steps:\n",
    "- Check the `./predictions/` folder for your test set predictions\n",
    "- Review training logs in TensorBoard: `tensorboard --logdir logs/`\n",
    "- Analyze model performance metrics\n",
    "- Fine-tune hyperparameters if needed\n",
    "\n",
    "### Model Performance Metrics:\n",
    "- Dice Score: Measures overlap between predicted and ground truth masks\n",
    "- IoU (Intersection over Union): Another overlap metric\n",
    "- Precision/Recall: Classification metrics for segmentation\n",
    "- F1 Score: Harmonic mean of precision and recall"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
